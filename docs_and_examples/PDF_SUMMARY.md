# üéâ PDF Support with Visual Understanding - Complete!

## What's New

Your RAG system now has **multimodal PDF processing** powered by [Qwen3-VL-Embedding-8B](https://huggingface.co/Qwen/Qwen3-VL-Embedding-8B)!

### Key Features

‚úÖ **Page-by-Page Processing** - Each PDF page converted to text + image  
‚úÖ **Visual Understanding** - Understands charts, diagrams, tables, figures  
‚úÖ **Multimodal Embeddings** - Text and visual content embedded together  
‚úÖ **Flexible Modes** - Choose multimodal, text-only, or image-only  
‚úÖ **Easy to Use** - Simple API and launcher scripts  

## Quick Start

### 1. Add Your PDFs

```powershell
# Create directory and add PDFs
mkdir sample_pdfs
copy your-document.pdf sample_pdfs\
```

### 2. Run the Example

```powershell
# Windows PowerShell
.\run.ps1 example-pdf

# Linux/Mac
./run.sh example-pdf
```

**That's it!** The system automatically:
- Installs dependencies (PyMuPDF, Pillow)
- Processes PDFs with visual understanding
- Creates multimodal embeddings
- Shows example queries

## How It Works

```
PDF Document
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Page 1 ‚îÄ‚îÄ‚ñ∫ Text: "Introduction..." 
     ‚îÇ             Image: [page rendering]
     ‚îÇ                      ‚Üì
     ‚îÇ              Qwen3-VL-Embedding
     ‚îÇ                      ‚Üì
     ‚îÇ              Multimodal Vector
     ‚îÇ
     ‚îú‚îÄ‚ñ∫ Page 2 ‚îÄ‚îÄ‚ñ∫ [Same process]
     ‚îÇ
     ‚îî‚îÄ‚ñ∫ Page N ‚îÄ‚îÄ‚ñ∫ [Same process]
                        ‚Üì
                  Vector Store
                  (FAISS or Milvus)
                        ‚Üì
                     Query ‚îÄ‚îÄ‚ñ∫ Retrieved Pages
                               (Text + Images)
```

## Simple Example

```python
from multimodal_rag import MultimodalRAGEngine

# Initialize
rag = MultimodalRAGEngine()

# Process PDF (text + images)
rag.ingest_pdf('report.pdf', mode='multimodal')

# Query with visual understanding
result = rag.query("What information is shown in the charts?")

# Access results
for chunk in result['retrieved_chunks']:
    print(f"Page {chunk['metadata']['page_number']}")
    print(f"Text: {chunk['text'][:200]}")
    
    # The page image is available!
    if chunk['has_image']:
        chunk['image'].show()  # Display it
        # or chunk['image'].save('page.png')  # Save it
```

## Processing Modes

### Multimodal (Recommended)
```python
rag.ingest_pdf('doc.pdf', mode='multimodal')
```
- Uses both text AND images
- Best for documents with visual content
- Understands charts, diagrams, tables

### Text-Only
```python
rag.ingest_pdf('doc.pdf', mode='text-only')
```
- Only extracted text
- Faster processing
- Good for text-heavy documents

### Image-Only
```python
rag.ingest_pdf('doc.pdf', mode='image-only')
```
- Only page images
- Good for scanned documents
- Handwriting recognition

## Advanced Features

### Custom DPI
```python
# Higher quality (slower)
rag = MultimodalRAGEngine(pdf_dpi=300)

# Faster processing (lower quality)
rag = MultimodalRAGEngine(pdf_dpi=100)
```

### Process Specific Pages
```python
# First 5 pages only
rag.ingest_pdf('large.pdf', pages=[1, 2, 3, 4, 5])

# Specific pages
rag.ingest_pdf('doc.pdf', pages=[10, 15, 20])
```

### Process Directory
```python
# All PDFs in a directory
rag.ingest_pdf_directory('./documents')

# With custom mode
rag.ingest_pdf_directory('./research_papers', mode='multimodal')
```

### With Milvus for Scale
```python
# Production setup
rag = MultimodalRAGEngine(
    vector_store_type='milvus',
    pdf_dpi=150
)

rag.ingest_pdf_directory('./large_collection')
```

## Use Cases

### üìö Research Papers
```python
rag.ingest_pdf_directory('./papers')
result = rag.query("Show papers with neural network diagrams")
```

### üìä Financial Reports
```python
rag.ingest_pdf('annual_report.pdf')
result = rag.query("What does the revenue chart show?")
```

### üìñ Technical Manuals
```python
rag.ingest_pdf('manual.pdf')
result = rag.query("Show the assembly diagram")
```

### üéì Textbooks
```python
rag.ingest_pdf_directory('./textbooks')
result = rag.query("Explain the cell structure diagram")
```

## Integration with LLMs

```python
from multimodal_rag import MultimodalRAGEngine
import openai

# Setup RAG
rag = MultimodalRAGEngine()
rag.ingest_pdf('document.pdf', mode='multimodal')

# Query
result = rag.query("Summarize the key findings", top_k=5)

# Build context
context_parts = []
for chunk in result['retrieved_chunks']:
    page = chunk['metadata']['page_number']
    context_parts.append(f"[Page {page}]\n{chunk['text']}\n")

context = "\n---\n".join(context_parts)

# Send to LLM
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": f"Answer based on:\n{context}"},
        {"role": "user", "content": result['question']}
    ]
)

print(response.choices[0].message.content)
```

## File Structure

### New Files
- `pdf_processor.py` - PDF to image conversion
- `multimodal_rag.py` - Multimodal RAG engine
- `example_pdf.py` - PDF example
- `PDF_GUIDE.md` - Complete documentation
- `sample_pdfs/` - Directory for PDF files

### Updated Files
- `embedding_client.py` - Added multimodal support
- `requirements.txt` - Added PyMuPDF, Pillow
- `run.ps1`, `run.sh`, `run.bat` - Added example-pdf command
- `CHANGELOG.md` - Version 2.2.0
- `README.md` - Added PDF features

## Dependencies

Automatically installed when you run the example:

```
PyMuPDF==1.23.26  # PDF processing
Pillow==10.2.0    # Image handling
```

Or install manually:
```powershell
pip install PyMuPDF Pillow
```

## Commands

```powershell
# Windows PowerShell
.\run.ps1 example-pdf        # Run PDF example
.\run.ps1 ingest sample_pdfs # Ingest PDFs (coming soon)

# Linux/Mac
./run.sh example-pdf         # Run PDF example
./run.sh ingest sample_pdfs  # Ingest PDFs (coming soon)
```

## Why This Matters

Traditional RAG systems lose valuable information from PDFs:

‚ùå **Before**: Only text extraction
- Misses charts and graphs
- Loses table formatting
- Ignores diagrams and flowcharts
- Can't understand visual context

‚úÖ **Now**: Multimodal understanding
- Understands visual content
- Captures charts and diagrams
- Recognizes tables and layouts
- Full visual context retained

## Performance

| DPI | Quality | Speed | File Size | Use Case |
|-----|---------|-------|-----------|----------|
| 72  | Low | Fast | Small | Text documents |
| 150 | Good | Medium | Medium | **Recommended** |
| 200 | High | Slow | Large | Visual-heavy docs |
| 300 | Very High | Very Slow | Very Large | Print quality |

## Documentation

- **Complete Guide**: [PDF_GUIDE.md](PDF_GUIDE.md)
- **Main README**: [README.md](README.md)
- **Quick Reference**: [QUICK_REFERENCE.md](QUICK_REFERENCE.md)
- **Qwen3-VL Info**: https://huggingface.co/Qwen/Qwen3-VL-Embedding-8B

## Summary

üéâ **Your RAG system is now multimodal!**

- ‚úÖ Process PDFs with visual understanding
- ‚úÖ Leverage Qwen3-VL's powerful capabilities
- ‚úÖ Easy to use with launcher scripts
- ‚úÖ Flexible configuration options
- ‚úÖ Production-ready with FAISS or Milvus

**Try it now:**
```powershell
.\run.ps1 example-pdf
```

---

**Version**: 2.2.0  
**Model**: [Qwen3-VL-Embedding-8B](https://huggingface.co/Qwen/Qwen3-VL-Embedding-8B)  
**Status**: Production Ready üöÄ
